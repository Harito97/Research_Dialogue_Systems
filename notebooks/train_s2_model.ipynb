{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, TimeDistributed, GlobalAveragePooling1D, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report, multilabel_classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo từ điển ánh xạ nhãn BIO thành chỉ số\n",
    "bio_labels = [\n",
    "    \"O\",\n",
    "    \"B-address\", \"B-area\", \"B-arriveby\", \"B-bookday\", \"B-bookpeople\", \"B-bookstay\", \"B-booktime\",\n",
    "    \"B-choice\", \"B-day\", \"B-department\", \"B-departure\", \"B-destination\", \"B-duration\", \"B-entrancefee\", \n",
    "    \"B-food\", \"B-leaveat\", \"B-name\", \"B-openhours\", \"B-phone\", \"B-postcode\", \"B-price\", \"B-pricerange\", \n",
    "    \"B-ref\", \"B-stars\", \"B-trainid\", \"B-type\", \"I-address\", \"I-area\", \"I-arriveby\", \"I-bookday\", \n",
    "    \"I-bookpeople\", \"I-bookstay\", \"I-booktime\", \"I-choice\", \"I-day\", \"I-department\", \"I-departure\", \n",
    "    \"I-destination\", \"I-duration\", \"I-entrancefee\", \"I-food\", \"I-leaveat\", \"I-name\", \"I-openhours\", \n",
    "    \"I-phone\", \"I-postcode\", \"I-price\", \"I-pricerange\", \"I-ref\", \"I-stars\", \"I-trainid\", \"I-type\"\n",
    "]\n",
    "\n",
    "# Tạo từ điển ánh xạ nhãn act type thành chỉ số\n",
    "unique_act_types = [\n",
    "    \"None\", \"Attraction-Inform\", \"Attraction-NoOffer\", \"Attraction-Recommend\", \"Attraction-Select\",\n",
    "    \"Booking-Book\", \"Booking-Inform\", \"Booking-NoBook\", \"Hospital-Inform\", \"Hotel-Inform\", \"Hotel-NoOffer\", \n",
    "    \"Hotel-Recommend\", \"Hotel-Select\", \"Police-Inform\", \"Restaurant-Inform\", \"Restaurant-NoOffer\", \n",
    "    \"Restaurant-Recommend\", \"Restaurant-Select\", \"Taxi-Inform\", \"Train-Inform\", \"Train-NoOffer\", \n",
    "    \"Train-OfferBook\", \"Train-OfferBooked\", \"Train-Select\"\n",
    "]\n",
    "\n",
    "def load_json(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def create_bio_labels(utterance, spans, slot_names):\n",
    "    # Tách câu thành các token\n",
    "    tokens = re.findall(r'\\w+|[^\\w\\s]', utterance, re.UNICODE)\n",
    "    \n",
    "    # Khởi tạo nhãn BIO cho các token\n",
    "    bio_labels = ['O'] * len(tokens)\n",
    "    \n",
    "    # Duyệt qua từng span\n",
    "    for start, end, slot_name in zip(spans['span_start'], spans['span_end'], slot_names):\n",
    "        # Xác định vị trí token đầu tiên và cuối cùng của span\n",
    "        token_start = len(re.findall(r'\\w+|[^\\w\\s]', utterance[:start]))\n",
    "        token_end = len(re.findall(r'\\w+|[^\\w\\s]', utterance[:end]))\n",
    "        \n",
    "        # Gán nhãn BIO cho các token trong span\n",
    "        if token_start < len(tokens):\n",
    "            bio_labels[token_start] = f'B-{slot_name}'\n",
    "        for i in range(token_start + 1, min(token_end, len(tokens))):\n",
    "            bio_labels[i] = f'I-{slot_name}'\n",
    "    \n",
    "    return tokens, bio_labels\n",
    "\n",
    "def get_raw_data1(dataset):\n",
    "    data_train = []\n",
    "    data_validation = []\n",
    "    data_test = []\n",
    "\n",
    "    for split in [\"train\", \"validation\", \"test\"]:\n",
    "        if split == \"train\":\n",
    "            data = data_train\n",
    "        elif split == \"validation\":\n",
    "            data = data_validation\n",
    "        elif split == \"test\":\n",
    "            data = data_test\n",
    "\n",
    "        for index_dialogue in range(len(dataset[split][\"dialogue_id\"])):\n",
    "            dialogue_id = dataset[split][\"dialogue_id\"][index_dialogue]\n",
    "            for index_turn in range(len(dataset[split][\"turns\"][index_dialogue]['turn_id'])):\n",
    "                record = [None] * 4\n",
    "                record[0] = dialogue_id\n",
    "                record[1] = dataset[split][\"turns\"][index_dialogue][\"turn_id\"][index_turn]\n",
    "                record[2] = dataset[split][\"turns\"][index_dialogue][\"utterance\"][index_turn]\n",
    "                record[3] = dataset[split][\"turns\"][index_dialogue][\"dialogue_acts\"][index_turn][\"span_info\"]\n",
    "                data.append(record)\n",
    "\n",
    "    return data_train, data_validation, data_test\n",
    "\n",
    "\n",
    "def get_raw_data2(data):\n",
    "    # data is data_train, data_validation, or data_test\n",
    "    X_token_classification = []\n",
    "    y_token_classification = []\n",
    "    y_act = []\n",
    "\n",
    "    # Tạo từ điển ánh xạ nhãn BIO thành chỉ số\n",
    "    label_to_id = {label: idx for idx, label in enumerate(bio_labels)}\n",
    "\n",
    "    # Tạo từ điển ánh xạ nhãn act_type thành chỉ số\n",
    "    act_type_to_id = {act_type: idx for idx, act_type in enumerate(unique_act_types)}\n",
    "\n",
    "    # Lặp qua các dữ liệu train\n",
    "    for item in data:\n",
    "        # Câu thoại (utterance)\n",
    "        utterance = item[2]  # Câu trong vị trí thứ 2\n",
    "\n",
    "        # Các nhãn act_type và act_slot_name từ `dialogue_acts`\n",
    "        dialogue_acts = item[3]  # Nhận phần dialogue_acts\n",
    "        span_start = dialogue_acts[\"span_start\"]\n",
    "        span_end = dialogue_acts[\"span_end\"]\n",
    "        act_slot_name = dialogue_acts[\"act_slot_name\"]\n",
    "        act_type = dialogue_acts[\"act_type\"]  # Nhãn act_type\n",
    "\n",
    "        # Gán nhãn BIO cho các token trong câu\n",
    "        tokens, bio_labels_for_tokens = create_bio_labels(\n",
    "            utterance, {\"span_start\": span_start, \"span_end\": span_end}, act_slot_name\n",
    "        )\n",
    "\n",
    "        # Lưu các token và nhãn BIO\n",
    "        X_token_classification.append(tokens)\n",
    "\n",
    "        # Chuyển nhãn BIO thành chỉ số\n",
    "        y_token_classification.append(\n",
    "            [label_to_id[label] for label in bio_labels_for_tokens]\n",
    "        )\n",
    "\n",
    "        # Khởi tạo ma trận one-hot cho các hành động\n",
    "        act_type_one_hot = np.zeros(len(unique_act_types))\n",
    "\n",
    "        # Nếu có nhiều hành động, đặt giá trị 1 cho những hành động xuất hiện trong `act_type`\n",
    "        for act in act_type:\n",
    "            act_type_id = act_type_to_id[act]\n",
    "            act_type_one_hot[act_type_id] = 1  # Gán 1 cho các vị trí của các hành động xuất hiện\n",
    "\n",
    "        # Append vào y_act\n",
    "        y_act.append(act_type_one_hot)\n",
    "\n",
    "    return X_token_classification, y_token_classification, y_act\n",
    "\n",
    "def get_raw_data():\n",
    "    dataset = load_json('dataset_multiwoz.json')\n",
    "    data_train, data_validation, data_test = get_raw_data1(dataset)\n",
    "    X_train, y_train, y_train_act = get_raw_data2(data_train)\n",
    "    X_validation, y_validation, y_validation_act = get_raw_data2(data_validation)\n",
    "    X_test, y_test, y_test_act = get_raw_data2(data_test)\n",
    "    return X_train, y_train_slot, y_train_act, X_validation, y_validation_slot, y_validation_act, X_test, y_test_slot, y_test_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train_slot, y_train_act, X_validation, y_validation_slot, y_validation_act, X_test, y_test_slot, y_test_act = get_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_hyperparameters(embedding_dim, max_sequence_length, num_classes_act, num_classes_slot, dropout_rate):\n",
    "    # Hyperparameters\n",
    "    EMBEDDING_DIM = embedding_dim\n",
    "    MAX_SEQUENCE_LENGTH = max_sequence_length\n",
    "    NUM_CLASSES_ACT = num_classes_act\n",
    "    NUM_CLASSES_SLOT = num_classes_slot\n",
    "    DROPOUT_RATE = dropout_rate\n",
    "    return EMBEDDING_DIM, MAX_SEQUENCE_LENGTH, NUM_CLASSES_ACT, NUM_CLASSES_SLOT, DROPOUT_RATE\n",
    "\n",
    "EMBEDDING_DIM, MAX_SEQUENCE_LENGTH, NUM_CLASSES_ACT, NUM_CLASSES_SLOT, DROPOUT_RATE = setup_hyperparameters(100, 50, 25, 50, 0.2)\n",
    "\n",
    "# Sử dụng BERT embedding (với `bert-base-uncased`)\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "bert_model_name = 'bert-base-uncased'\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "bert_model = TFBertModel.from_pretrained(bert_model_name)\n",
    "\n",
    "def create_bert_embedding(texts):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for text in texts:\n",
    "        encoded_dict = bert_tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_SEQUENCE_LENGTH,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='tf'\n",
    "        )\n",
    "        input_ids.append(encoded_dict['input_ids'][0])\n",
    "        attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "    input_ids = tf.stack(input_ids)\n",
    "    attention_masks = tf.stack(attention_masks)\n",
    "    embeddings = bert_model(input_ids, attention_mask=attention_masks)[0]\n",
    "    return embeddings\n",
    "\n",
    "X_train_bert = create_bert_embedding(X_train)\n",
    "X_val_bert = create_bert_embedding(X_validation)\n",
    "X_test_bert = create_bert_embedding(X_test)\n",
    "\n",
    "# Chuẩn bị dữ liệu (Padding và one-hot encoding)\n",
    "y_train_padded = pad_sequences(y_token_classification_train, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "y_train_padded_one_hot = np.array([to_categorical(y, num_classes=num_slot_labels) for y in y_train_padded])\n",
    "\n",
    "y_val_padded = pad_sequences(y_token_classification_val, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "y_val_padded_one_hot = np.array([to_categorical(y, num_classes=num_slot_labels) for y in y_val_padded])\n",
    "\n",
    "y_test_padded = pad_sequences(y_token_classification_test, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "y_test_padded_one_hot = np.array([to_categorical(y, num_classes=num_slot_labels) for y in y_test_padded])\n",
    "\n",
    "y_act_one_hot = np.array(y_act_train)\n",
    "y_act_val_one_hot = np.array(y_act_val)\n",
    "y_act_test_one_hot = np.array(y_act_test)\n",
    "\n",
    "# Tính class weights cho slot classification\n",
    "from sklearn.utils import class_weight\n",
    "slot_class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_padded.flatten()), y=y_train_padded.flatten())\n",
    "slot_class_weights_dict = dict(enumerate(slot_class_weights))\n",
    "\n",
    "# Tính class weights cho act type classification (multi-label)\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_act_mlb = mlb.fit_transform([np.where(r==1)[0] for r in y_act_one_hot])\n",
    "act_class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_act_mlb.flatten()), y=y_act_mlb.flatten())\n",
    "act_class_weights_dict = dict(enumerate(act_class_weights))\n",
    "\n",
    "# Model (Sử dụng BERT embedding và dropout)\n",
    "input_seq = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=\"int32\")\n",
    "embedding = bert_model(input_seq)[0]\n",
    "bilstm = Bidirectional(LSTM(128, return_sequences=True))(embedding) # Tăng số units\n",
    "bilstm = Dropout(DROPOUT_RATE)(bilstm) # Thêm dropout\n",
    "\n",
    "slot_output = TimeDistributed(Dense(NUM_CLASSES_SLOT, activation=\"softmax\"), name=\"slot_output\")(bilstm)\n",
    "\n",
    "sentence_representation = GlobalAveragePooling1D()(bilstm)\n",
    "sentence_representation = Dropout(DROPOUT_RATE)(sentence_representation) # Thêm dropout\n",
    "action_output = Dense(NUM_CLASSES_ACT, activation=\"sigmoid\", name=\"action_output\")(sentence_representation) # Sigmoid cho multi-label\n",
    "\n",
    "model = Model(inputs=input_seq, outputs=[slot_output, action_output])\n",
    "\n",
    "# Compile model với class weights\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"slot_output\": \"categorical_crossentropy\",\n",
    "        \"action_output\": \"binary_crossentropy\", # Binary crossentropy cho multi-label\n",
    "    },\n",
    "    loss_weights={\n",
    "        \"slot_output\": 1.0,\n",
    "        \"action_output\": 1.0\n",
    "    },\n",
    "    metrics={\"slot_output\": [\"accuracy\"], \"action_output\": [\"binary_accuracy\"]}, # Binary accuracy cho multi-label\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "history = model.fit(\n",
    "    X_train_bert,\n",
    "    [y_train_padded_one_hot, y_act_one_hot],\n",
    "    validation_data=(X_val_bert, [y_val_padded_one_hot, y_act_val_one_hot]),\n",
    "    epochs=20, # Tăng số epochs\n",
    "    batch_size=32, # Giảm batch size nếu cần\n",
    "    class_weight=[slot_class_weights_dict, act_class_weights_dict]\n",
    ")\n",
    "\n",
    "# Đánh giá và in report (chỉnh sửa cho multi-label)\n",
    "y_pred_slot, y_pred_action = model.predict(X_test_bert)\n",
    "\n",
    "y_pred_slot_labels = np.argmax(y_pred_slot, axis=-1)\n",
    "y_true_slot_labels = np.argmax(y_test_padded_one_hot, axis=-1)\n",
    "y_pred_slot_flatten = y_pred_slot_labels.reshape(-1)\n",
    "y_true_slot_flatten = y_true_slot_labels.reshape(-1)\n",
    "\n",
    "print(\"Slot Classification Metrics:\")\n",
    "print(classification_report(y_true_slot_flatten, y_pred_slot_flatten, zero_division=0))\n",
    "\n",
    "y_pred_action_labels = (y_pred_action > 0.5).astype(int) # Ngưỡng 0.5 cho sigmoid\n",
    "print(\"Action Classification Metrics:\")\n",
    "print(multilabel_classification_report(y_act_test_one_hot, y_pred_action_labels, zero_division=0))\n",
    "\n",
    "# ... (Phần test với câu mẫu giữ nguyên, chỉ cần thay X_train_padded bằng X_train_bert)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_work#311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
